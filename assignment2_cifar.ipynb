{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import struct\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy.linalg as lng\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset_cifar = np.load('cifar_dataset.npz')\n",
    "Xtr = dataset_cifar['Xtr']    #training data\n",
    "Str = dataset_cifar['Str']    #training label\n",
    "Xts = dataset_cifar['Xts']    #test data\n",
    "Yts = dataset_cifar['Yts']    #test label\n",
    "print(Xtr.shape)\n",
    "print(Str.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_cnn = Xtr.reshape(len(Xtr), 32, 32, 3).astype(np.float32) / 255.0\n",
    "Xts_cnn = Xts.reshape(len(Xts), 32, 32, 3).astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Str_cnn = keras.utils.to_categorical(Str, 2)\n",
    "Yts_cnn = keras.utils.to_categorical(Yts, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Form convolutional neural network\n",
    "\n",
    "model_training = keras.Sequential([\n",
    "    \n",
    "    keras.layers.Conv2D(32, (5, 5), use_bias=True, padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(32, (5, 5), use_bias=True, padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Dropout(0.15),\n",
    "    \n",
    "    keras.layers.Conv2D(64, (5, 5), use_bias=True, padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(64, (5, 5), use_bias=True, padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Dropout(0.15),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu', use_bias=True),\n",
    "    keras.layers.Dropout(0.15),\n",
    "\n",
    "    keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "    \n",
    "])\n",
    "model_training.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.6679 - acc: 0.6014\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 9s 906us/step - loss: 0.6480 - acc: 0.6080\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 9s 909us/step - loss: 0.6401 - acc: 0.6189\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 9s 907us/step - loss: 0.6365 - acc: 0.6293\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 9s 908us/step - loss: 0.6332 - acc: 0.6328\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 9s 912us/step - loss: 0.6312 - acc: 0.6386\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 9s 919us/step - loss: 0.6307 - acc: 0.6393\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 9s 915us/step - loss: 0.6257 - acc: 0.6471\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 9s 924us/step - loss: 0.6230 - acc: 0.6505\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 9s 926us/step - loss: 0.6198 - acc: 0.6578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a35a84780>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_training.fit(Xtr_cnn,Str_cnn,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.63380635 0.36619362]\n",
      " [0.42604744 0.57395256]\n",
      " [0.64660466 0.35339537]\n",
      " [0.56657803 0.4334219 ]\n",
      " [0.6396351  0.36036494]]\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "prediction_train = model_training.predict(Xtr_cnn)\n",
    "print(prediction_train[:5])\n",
    "print(prediction_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42604744\n",
      "0.36619362\n"
     ]
    }
   ],
   "source": [
    "p0 = np.min(prediction_train[1]) \n",
    "p1 = np.min(prediction_train[0]) \n",
    "print(p0)\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatebeta (Str,prediction,p0,p1): \n",
    "    beta = np.zeros((len(prediction ),1)) \n",
    "    for i in range(len(prediction)): \n",
    "        if Str[i] == 0 : \n",
    "            beta[i] = ((prediction[i][0] - p1) / ((1 - p0 - p1) * prediction[i][0]))\n",
    "        else:\n",
    "            beta[i] = ((prediction[i][1] - p0) / ((1 - p0 - p1) * prediction[i][1]))\n",
    "    return beta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.03231241]\n",
      " [0.67619852]\n",
      " [0.        ]\n",
      " [0.08189549]\n",
      " [2.05765417]]\n"
     ]
    }
   ],
   "source": [
    "beta = generatebeta (Str,prediction_train,p0,p1)\n",
    "\n",
    "for i in range(len(beta)):\n",
    "    if beta[i] < 0:\n",
    "        beta[i] = 0.0\n",
    "\n",
    "print(beta[:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Form convolutional neural network for important reweighting\n",
    "\n",
    "model_beta = keras.Sequential([\n",
    "    \n",
    "    keras.layers.Conv2D(32, (5, 5), use_bias=True, padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(32, (5, 5), use_bias=True, padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Dropout(0.15),\n",
    "    \n",
    "    keras.layers.Conv2D(64, (5, 5), use_bias=True, padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(64, (5, 5), use_bias=True, padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Dropout(0.15),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu', use_bias=True),\n",
    "    keras.layers.Dropout(0.15),\n",
    "\n",
    "    keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "    \n",
    "])\n",
    "model_beta.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3783 - acc: 0.6262\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 10s 997us/step - loss: 0.2832 - acc: 0.6499\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2594 - acc: 0.6630\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 10s 981us/step - loss: 0.2523 - acc: 0.6701\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 9s 947us/step - loss: 0.2385 - acc: 0.6748\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 10s 952us/step - loss: 0.2334 - acc: 0.6801\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2225 - acc: 0.6893\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2105 - acc: 0.7016\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2023 - acc: 0.7097\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 9s 939us/step - loss: 0.1892 - acc: 0.7188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a859aaf28>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_beta.fit(Xtr_cnn,Str_cnn,sample_weight = beta.flatten(),epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9904114e-01 9.5881277e-04]\n",
      " [9.9510926e-01 4.8907311e-03]\n",
      " [9.3825646e-02 9.0617430e-01]\n",
      " [9.8678023e-01 1.3219710e-02]\n",
      " [7.5820833e-02 9.2417920e-01]]\n",
      "(2000, 2)\n",
      "[0, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "#Use CNN to predict \n",
    "prediction_test_b = model_beta.predict(Xts_cnn)\n",
    "\n",
    "print(prediction_test_b[:5])\n",
    "print(prediction_test_b.shape)\n",
    "\n",
    "pred_Y_b = []\n",
    "\n",
    "for i in range(len(prediction_test_b)):\n",
    "    pred_Y_b.append(np.argmax(prediction_test_b[i]))\n",
    "\n",
    "print(pred_Y_b[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAccuracy(Y,pred_Y):\n",
    "    acc = 0.0\n",
    "    for i in range(len(Y)):\n",
    "        if Y[i] == pred_Y[i]:\n",
    "            acc += 1.0\n",
    "    return acc/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "acc_b = computeAccuracy(Yts,pred_Y_b)\n",
    "print(acc_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatealpha(p0,p1):\n",
    "    alpha = ((1-p1+p0) / 2)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5299269109964371\n"
     ]
    }
   ],
   "source": [
    "alpha = generatealpha(p0,p1)\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[0.52992691]\n",
      " [0.52992691]\n",
      " [0.47007309]\n",
      " [0.47007309]\n",
      " [0.52992691]]\n"
     ]
    }
   ],
   "source": [
    "alpha_weight = np.zeros((len(Str),1)) \n",
    "\n",
    "for i in range(len(Str)):\n",
    "    if Str[i] == 1:\n",
    "        alpha_weight[i] = 1-alpha\n",
    "    else:\n",
    "        alpha_weight[i] = alpha\n",
    "\n",
    "print(type(alpha_weight))\n",
    "print(alpha_weight[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Form convolutional neural network for unbaised estimator\n",
    "\n",
    "model_alpha = keras.Sequential([\n",
    "    \n",
    "    keras.layers.Conv2D(32, (5, 5), use_bias=True, padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(32, (5, 5), use_bias=True, padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Dropout(0.15),\n",
    "    \n",
    "    keras.layers.Conv2D(64, (5, 5), use_bias=True, padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(64, (5, 5), use_bias=True, padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Dropout(0.15),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu', use_bias=True),\n",
    "    keras.layers.Dropout(0.15),\n",
    "\n",
    "    keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "    \n",
    "])\n",
    "model_alpha.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6507 - acc: 0.6001\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 9s 912us/step - loss: 0.6341 - acc: 0.6076\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 9s 914us/step - loss: 0.6244 - acc: 0.6227\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 9s 920us/step - loss: 0.6269 - acc: 0.6214\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 9s 918us/step - loss: 0.6197 - acc: 0.6358\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 9s 924us/step - loss: 0.6149 - acc: 0.6463\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 9s 933us/step - loss: 0.6093 - acc: 0.6531\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 9s 932us/step - loss: 0.6091 - acc: 0.6542\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 9s 945us/step - loss: 0.6033 - acc: 0.6617\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 9s 936us/step - loss: 0.6010 - acc: 0.6654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a87db1d30>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_alpha.fit(Xtr_cnn,Str_cnn,sample_weight = alpha_weight.flatten(),epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75482833 0.24517162]\n",
      " [0.5299941  0.47000593]\n",
      " [0.43163976 0.56836027]\n",
      " [0.44965598 0.550344  ]\n",
      " [0.49961835 0.5003816 ]]\n",
      "(2000, 2)\n",
      "[0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "prediction_test_a = model_alpha.predict(Xts_cnn)\n",
    "\n",
    "print(prediction_test_a[:5])\n",
    "print(prediction_test_a.shape)\n",
    "\n",
    "pred_Y_a = []\n",
    "\n",
    "for i in range(len(prediction_test_a)):\n",
    "    pred_Y_a.append(np.argmax(prediction_test_a[i]))\n",
    "\n",
    "print(pred_Y_a[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.761\n"
     ]
    }
   ],
   "source": [
    "acc_a = computeAccuracy(Yts,pred_Y_a)\n",
    "print(acc_a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
